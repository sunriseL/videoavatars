{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "import chumpy as ch\n",
    "import cPickle as pkl\n",
    "\n",
    "from opendr.camera import ProjectPoints\n",
    "from opendr.lighting import LambertianPointLight\n",
    "from opendr.renderer import ColoredRenderer\n",
    "from opendr.filters import gaussian_pyramid\n",
    "\n",
    "from util import im\n",
    "from util.logger import log\n",
    "from lib.frame import FrameData\n",
    "from models.smpl import Smpl, copy_smpl, joints_coco\n",
    "from models.bodyparts import faces_no_hands\n",
    "\n",
    "from vendor.smplify.sphere_collisions import SphereCollisions\n",
    "from vendor.smplify.robustifiers import GMOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb(viz_rn, f):\n",
    "    if viz_rn is not None:\n",
    "        viz_rn.set(v=f.smpl, background_image=np.dstack((f.mask, f.mask, f.mask)))\n",
    "        viz_rn.vc.set(v=f.smpl)\n",
    "\n",
    "        def cb(_):\n",
    "            debug = np.array(viz_rn.r)\n",
    "\n",
    "            for j in f.J_proj.r:\n",
    "                cv2.circle(debug, tuple(j.astype(np.int)), 3, (0, 0, 0.8), -1)\n",
    "            for j in f.keypoints[:, :2]:\n",
    "                cv2.circle(debug, tuple(j.astype(np.int)), 3, (0, 0.8, 0), -1)\n",
    "\n",
    "            im.show(debug, id='pose', waittime=1)\n",
    "    else:\n",
    "        cb = None\n",
    "\n",
    "    return cb\n",
    "\n",
    "\n",
    "def collision_obj(smpl, regs):\n",
    "    sp = SphereCollisions(pose=smpl.pose, betas=smpl.betas, model=smpl, regs=regs)\n",
    "    sp.no_hands = True\n",
    "\n",
    "    return sp\n",
    "\n",
    "\n",
    "def pose_prior_obj(smpl, prior_data):\n",
    "    return (smpl.pose[3:] - prior_data['mean']).reshape(1, -1).dot(prior_data['prec'])\n",
    "\n",
    "\n",
    "def height_predictor(b2m, betas):\n",
    "    return ch.hstack((betas.reshape(1, -1), [[1]])).dot(b2m)\n",
    "\n",
    "\n",
    "def init(frames, body_height, b2m, viz_rn):\n",
    "    betas = frames[0].smpl.betas\n",
    "\n",
    "    E_height = None\n",
    "    if body_height is not None:\n",
    "         E_height = height_predictor(b2m, betas) - body_height * 1000.\n",
    "\n",
    "    # first get a rough pose for all frames individually\n",
    "    for i, f in enumerate(frames):\n",
    "        if np.sum(f.keypoints[[0, 2, 5, 8, 11], 2]) > 3.:\n",
    "            if f.keypoints[2, 0] > f.keypoints[5, 0]:\n",
    "                f.smpl.pose[0] = 0\n",
    "                f.smpl.pose[2] = np.pi\n",
    "\n",
    "            E_init = {\n",
    "                'init_pose_{}'.format(i): f.pose_obj[[0, 2, 5, 8, 11]]\n",
    "            }\n",
    "\n",
    "            x0 = [f.smpl.trans, f.smpl.pose[:3]]\n",
    "\n",
    "            if E_height is not None and i == 0:\n",
    "                E_init['height'] = E_height\n",
    "                E_init['betas'] = betas\n",
    "                x0.append(betas)\n",
    "\n",
    "            ch.minimize(\n",
    "                E_init,\n",
    "                x0,\n",
    "                method='dogleg',\n",
    "                options={\n",
    "                    'e_3': .01,\n",
    "                },\n",
    "                callback=get_cb(viz_rn, f)\n",
    "            )\n",
    "\n",
    "    weights = zip(\n",
    "        [5., 4.5, 4.],\n",
    "        [5., 4., 3.]\n",
    "    )\n",
    "\n",
    "    E_betas = betas - betas.r\n",
    "\n",
    "    for w_prior, w_betas in weights:\n",
    "        x0 = [betas]\n",
    "\n",
    "        E = {\n",
    "            'betas': E_betas * w_betas,\n",
    "        }\n",
    "\n",
    "        if E_height is not None:\n",
    "            E['height'] = E_height\n",
    "\n",
    "        for i, f in enumerate(frames):\n",
    "            if np.sum(f.keypoints[[0, 2, 5, 8, 11], 2]) > 3.:\n",
    "                x0.extend([f.smpl.pose[range(21) + range(27, 30) + range(36, 60)], f.smpl.trans])\n",
    "                E['pose_{}'.format(i)] = f.pose_obj\n",
    "                E['prior_{}'.format(i)] = f.pose_prior_obj * w_prior\n",
    "\n",
    "        ch.minimize(\n",
    "            E,\n",
    "            x0,\n",
    "            method='dogleg',\n",
    "            options={\n",
    "                'e_3': .01,\n",
    "            },\n",
    "            callback=get_cb(viz_rn, frames[0])\n",
    "        )\n",
    "\n",
    "\n",
    "def reinit_frame(frame, null_pose, nohands, viz_rn):\n",
    "\n",
    "    if (np.sum(frame.pose_obj.r ** 2) > 625 or np.sum(frame.pose_prior_obj.r ** 2) > 75)\\\n",
    "            and np.sum(frame.keypoints[[0, 2, 5, 8, 11], 2]) > 3.:\n",
    "\n",
    "        log.info('Tracking error too large. Re-init frame...')\n",
    "\n",
    "        x0 = [frame.smpl.pose[:3], frame.smpl.trans]\n",
    "\n",
    "        frame.smpl.pose[3:] = null_pose\n",
    "        if frame.keypoints[2, 0] > frame.keypoints[5, 0]:\n",
    "            frame.smpl.pose[0] = 0\n",
    "            frame.smpl.pose[2] = np.pi\n",
    "\n",
    "        E = {\n",
    "            'init_pose': frame.pose_obj[[0, 2, 5, 8, 11]],\n",
    "        }\n",
    "\n",
    "        ch.minimize(\n",
    "            E,\n",
    "            x0,\n",
    "            method='dogleg',\n",
    "            options={\n",
    "                'e_3': .1,\n",
    "            },\n",
    "            callback=get_cb(viz_rn, frame)\n",
    "        )\n",
    "\n",
    "        E = {\n",
    "            'pose': GMOf(frame.pose_obj, 100),\n",
    "            'prior': frame.pose_prior_obj * 8.,\n",
    "        }\n",
    "\n",
    "        x0 = [frame.smpl.trans]\n",
    "\n",
    "        if nohands:\n",
    "            x0.append(frame.smpl.pose[range(21) + range(27, 30) + range(36, 60)])\n",
    "        else:\n",
    "            x0.append(frame.smpl.pose[range(21) + range(27, 30) + range(36, 72)])\n",
    "\n",
    "        ch.minimize(\n",
    "            E,\n",
    "            x0,\n",
    "            method='dogleg',\n",
    "            options={\n",
    "                'e_3': .01,\n",
    "            },\n",
    "            callback=get_cb(viz_rn, frame)\n",
    "        )\n",
    "\n",
    "\n",
    "def fit_pose(frame, last_smpl, frustum, nohands, viz_rn):\n",
    "\n",
    "    if nohands:\n",
    "        faces = faces_no_hands(frame.smpl.f)\n",
    "    else:\n",
    "        faces = frame.smpl.f\n",
    "\n",
    "    dst_type = cv2.cv.CV_DIST_L2 if cv2.__version__[0] == '2' else cv2.DIST_L2\n",
    "\n",
    "    dist_i = cv2.distanceTransform(np.uint8(frame.mask * 255), dst_type, 5) - 1\n",
    "    dist_i[dist_i < 0] = 0\n",
    "    dist_i[dist_i > 50] = 50\n",
    "    dist_o = cv2.distanceTransform(255 - np.uint8(frame.mask * 255), dst_type, 5)\n",
    "    dist_o[dist_o > 50] = 50\n",
    "\n",
    "    rn_m = ColoredRenderer(camera=frame.camera, v=frame.smpl, f=faces, vc=np.ones_like(frame.smpl), frustum=frustum,\n",
    "                           bgcolor=0, num_channels=1)\n",
    "\n",
    "    E = {\n",
    "        'mask': gaussian_pyramid(rn_m * dist_o * 100. + (1 - rn_m) * dist_i, n_levels=4, normalization='size') * 80.,\n",
    "        '2dpose': GMOf(frame.pose_obj, 100),\n",
    "        'prior': frame.pose_prior_obj * 4.,\n",
    "        'sp': frame.collision_obj * 1e3,\n",
    "    }\n",
    "\n",
    "    if last_smpl is not None:\n",
    "        E['last_pose'] = GMOf(frame.smpl.pose - last_smpl.pose, 0.05) * 50.\n",
    "        E['last_trans'] = GMOf(frame.smpl.trans - last_smpl.trans, 0.05) * 50.\n",
    "\n",
    "    if nohands:\n",
    "        x0 = [frame.smpl.pose[range(21) + range(27, 30) + range(36, 60)], frame.smpl.trans]\n",
    "    else:\n",
    "        x0 = [frame.smpl.pose[range(21) + range(27, 30) + range(36, 72)], frame.smpl.trans]\n",
    "\n",
    "    ch.minimize(\n",
    "        E,\n",
    "        x0,\n",
    "        method='dogleg',\n",
    "        options={\n",
    "            'e_3': .01,\n",
    "        },\n",
    "        callback=get_cb(viz_rn, frame)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipath = \"./dataset/female-3-sport/\"\n",
    "opath = \"./output/\"\n",
    "keypoint_file = ipath + \"keypoints.hdf5\"\n",
    "masks_file = ipath + \"masks.hdf5\"\n",
    "camera_file = ipath + \"camera.pkl\"\n",
    "out = opath + \"reconstructed_poses.hdf5\"\n",
    "model_file = 'vendor/smpl/models/basicmodel_m_lbs_10_207_0_v1.0.0.pkl'\n",
    "prior_file = 'assets/prior_a_pose.pkl'\n",
    "resize = 0.5\n",
    "body_height = None\n",
    "nohands = None\n",
    "display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#parameters of model\n",
    "with open(model_file, 'rb') as fp:\n",
    "    model_data = pkl.load(fp)\n",
    "\n",
    "#parameters of camera\n",
    "with open(camera_file, 'rb') as fp:\n",
    "    camera_data = pkl.load(fp)\n",
    "\n",
    "with open(prior_file, 'rb') as fp:\n",
    "    prior_data = pkl.load(fp)\n",
    "\n",
    "if 'basicModel_f' in model_file:\n",
    "    regs = np.load('vendor/smplify/models/regressors_locked_normalized_female.npz')\n",
    "    b2m = np.load('assets/b2m_f.npy')\n",
    "else:\n",
    "    regs = np.load('vendor/smplify/models/regressors_locked_normalized_male.npz')\n",
    "    b2m = np.load('assets/b2m_m.npy')\n",
    "\n",
    "#<HDF5 dataset \"keypoints\": shape (511, 54), type \"<f4\">\n",
    "keypoints = h5py.File(keypoint_file, 'r')['keypoints']\n",
    "\n",
    "#<HDF5 dataset \"masks\": shape (511, 1080, 1080), type \"|i1\">\n",
    "masks = h5py.File(masks_file, 'r')['masks']\n",
    "\n",
    "#num of frames = 511\n",
    "num_frames = masks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"keypoints\": shape (511, 54), type \"<f4\">\n",
      "<HDF5 dataset \"masks\": shape (511, 1080, 1080), type \"|i1\">\n"
     ]
    }
   ],
   "source": [
    "print(keypoints)\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init of SMPL model\n",
    "base_smpl = Smpl(model_data)\n",
    "base_smpl.trans[:] = np.array([0, 0, 3])\n",
    "base_smpl.pose[0] = np.pi\n",
    "base_smpl.pose[3:] = prior_data['mean']\n",
    "\n",
    "# <smpl.f> means face\n",
    "\n",
    "# use the data from camera.pkl to generate project points(that is the position of the camera)\n",
    "camera = ProjectPoints(t=np.zeros(3), rt=np.zeros(3), c=camera_data['camera_c'] * resize,\n",
    "                           f=camera_data['camera_f'] * resize, k=camera_data['camera_k'], v=base_smpl)\n",
    "frustum = {'near': 0.1, 'far': 1000.,\n",
    "    'width': int(camera_data['width'] * resize), 'height': int(camera_data['height'] * resize)}\n",
    "display=False\n",
    "if display:\n",
    "    debug_cam = ProjectPoints(v=base_smpl, t=camera.t, rt=camera.rt, c=camera.c, f=camera.f, k=camera.k)\n",
    "    debug_light = LambertianPointLight(f=base_smpl.f, v=base_smpl, num_verts=len(base_smpl), light_pos=np.zeros(3),\n",
    "                                           vc=np.ones(3), light_color=np.ones(3))\n",
    "    debug_rn = ColoredRenderer(camera=debug_cam, v=base_smpl, f=base_smpl.f, vc=debug_light, frustum=frustum)\n",
    "else:\n",
    "    debug_rn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic frame loading function\n",
    "def create_frame(i, smpl, copy=True):\n",
    "    f = FrameData()\n",
    "\n",
    "    f.smpl = copy_smpl(smpl, model_data) if copy else smpl\n",
    "    f.camera = ProjectPoints(v=f.smpl, t=camera.t, rt=camera.rt, c=camera.c, f=camera.f, k=camera.k)\n",
    "\n",
    "    f.keypoints = np.array(keypoints[i]).reshape(-1, 3) * np.array([resize, resize, 1])\n",
    "    f.J = joints_coco(f.smpl)\n",
    "    f.J_proj = ProjectPoints(v=f.J, t=camera.t, rt=camera.rt, c=camera.c, f=camera.f, k=camera.k)\n",
    "    f.mask = cv2.resize(np.array(masks[i], dtype=np.float32), (0, 0),\n",
    "        fx=resize, fy=resize, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    f.collision_obj = collision_obj(f.smpl, regs)\n",
    "    f.pose_prior_obj = pose_prior_obj(f.smpl, prior_data)\n",
    "    f.pose_obj = (f.J_proj - f.keypoints[:, :2]) * f.keypoints[:, 2].reshape(-1, 1)\n",
    "\n",
    "    return f\n",
    "\n",
    "base_frame = create_frame(0, base_smpl, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -37.01165423 -223.35057181]\n",
      " [ -41.72566925 -178.86834829]\n",
      " [ -64.04232201 -159.53792041]\n",
      " [ -86.48821999 -118.75679076]\n",
      " [-119.13060367  -93.58480347]\n",
      " [ -14.64364306 -159.90694275]\n",
      " [  19.62950611 -123.8800167 ]\n",
      " [  58.62309148 -117.16250645]\n",
      " [ -36.66026371  -53.05932856]\n",
      " [ -42.71252615  -13.1809011 ]\n",
      " [ -36.84122184   53.80872143]\n",
      " [ -14.37306846  -60.05237632]\n",
      " [  -7.17703133  -17.00611908]\n",
      " [ -11.81205606   56.80489621]\n",
      " [ -40.72825932 -219.51790077]\n",
      " [ -29.37081378 -215.19962711]\n",
      " [ -46.68374855 -198.6219922 ]\n",
      " [ -28.82030465 -230.47712397]]\n"
     ]
    }
   ],
   "source": [
    "print(base_frame.pose_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-19 02:48:25,713 [<ipython-input-29-5422d29e8dfb>:<module>:2] Initial fit\n",
      "1.15e+05 | init_pose_0: 1.15e+05\n",
      "8.99e+03 | init_pose_0: 8.99e+03\n",
      "2.54e+02 | init_pose_0: 2.54e+02\n",
      "2.70e+01 | init_pose_0: 2.70e+01\n",
      "2.67e+01 | init_pose_0: 2.67e+01\n",
      "2.67e+01 | init_pose_0: 2.67e+01\n",
      "9.83e+04 | init_pose_1: 9.83e+04\n",
      "1.09e+04 | init_pose_1: 1.09e+04\n",
      "8.30e+02 | init_pose_1: 8.30e+02\n",
      "1.77e+02 | init_pose_1: 1.77e+02\n",
      "1.73e+02 | init_pose_1: 1.73e+02\n",
      "1.73e+02 | init_pose_1: 1.73e+02\n",
      "1.01e+05 | init_pose_2: 1.01e+05\n",
      "1.22e+04 | init_pose_2: 1.22e+04\n",
      "7.95e+02 | init_pose_2: 7.95e+02\n",
      "6.89e+01 | init_pose_2: 6.89e+01\n",
      "6.10e+01 | init_pose_2: 6.10e+01\n",
      "6.10e+01 | init_pose_2: 6.10e+01\n",
      "1.17e+05 | init_pose_3: 1.17e+05\n",
      "1.01e+04 | init_pose_3: 1.01e+04\n",
      "3.01e+02 | init_pose_3: 3.01e+02\n",
      "9.98e+00 | init_pose_3: 9.98e+00\n",
      "9.52e+00 | init_pose_3: 9.52e+00\n",
      "9.52e+00 | init_pose_3: 9.52e+00\n",
      "6.04e+03 | betas: 0.00e+00 | pose_0: 1.91e+03 | pose_1: 1.20e+03 | pose_2: 2.24e+03 | pose_3: 6.94e+02 | prior_0: 0.00e+00 | prior_1: 0.00e+00 | prior_2: 0.00e+00 | prior_3: 0.00e+00\n",
      "2.06e+03 | betas: 3.71e+01 | pose_0: 8.46e+02 | pose_1: 2.88e+02 | pose_2: 4.42e+02 | pose_3: 1.66e+02 | prior_0: 5.58e+01 | prior_1: 6.07e+01 | prior_2: 1.32e+02 | prior_3: 3.23e+01\n",
      "1.36e+03 | betas: 3.82e+01 | pose_0: 1.79e+02 | pose_1: 2.79e+02 | pose_2: 4.21e+02 | pose_3: 1.28e+02 | prior_0: 8.06e+01 | prior_1: 6.20e+01 | prior_2: 1.35e+02 | prior_3: 3.29e+01\n",
      "1.34e+03 | betas: 3.88e+01 | pose_0: 1.68e+02 | pose_1: 2.76e+02 | pose_2: 4.18e+02 | pose_3: 1.23e+02 | prior_0: 7.45e+01 | prior_1: 6.21e+01 | prior_2: 1.39e+02 | prior_3: 3.52e+01\n",
      "1.33e+03 | betas: 3.83e+01 | pose_0: 1.65e+02 | pose_1: 2.76e+02 | pose_2: 4.18e+02 | pose_3: 1.23e+02 | prior_0: 7.63e+01 | prior_1: 6.21e+01 | prior_2: 1.40e+02 | prior_3: 3.54e+01\n",
      "1.26e+03 | betas: 2.45e+01 | pose_0: 1.65e+02 | pose_1: 2.76e+02 | pose_2: 4.18e+02 | pose_3: 1.23e+02 | prior_0: 6.18e+01 | prior_1: 5.03e+01 | prior_2: 1.13e+02 | prior_3: 2.87e+01\n",
      "1.25e+03 | betas: 4.54e+01 | pose_0: 1.50e+02 | pose_1: 2.51e+02 | pose_2: 3.78e+02 | pose_3: 1.12e+02 | prior_0: 7.06e+01 | prior_1: 6.42e+01 | prior_2: 1.44e+02 | prior_3: 3.36e+01\n",
      "1.16e+03 | betas: 2.56e+01 | pose_0: 1.50e+02 | pose_1: 2.51e+02 | pose_2: 3.78e+02 | pose_3: 1.12e+02 | prior_0: 5.58e+01 | prior_1: 5.07e+01 | prior_2: 1.14e+02 | prior_3: 2.66e+01\n",
      "1.14e+03 | betas: 5.57e+01 | pose_0: 1.31e+02 | pose_1: 2.19e+02 | pose_2: 3.31e+02 | pose_3: 9.80e+01 | prior_0: 6.54e+01 | prior_1: 6.59e+01 | prior_2: 1.47e+02 | prior_3: 3.08e+01\n",
      "1.14e+03 | betas: 5.92e+01 | pose_0: 1.30e+02 | pose_1: 2.17e+02 | pose_2: 3.29e+02 | pose_3: 9.68e+01 | prior_0: 6.60e+01 | prior_1: 6.61e+01 | prior_2: 1.48e+02 | prior_3: 3.08e+01\n"
     ]
    }
   ],
   "source": [
    "# get betas from 5 frames\n",
    "log.info('Initial fit')\n",
    "\n",
    "num_init = 5\n",
    "indices_init = np.ceil(np.arange(num_init) * num_frames * 1. / num_init).astype(np.int)\n",
    "\n",
    "init_frames = [base_frame]\n",
    "for i in indices_init[1:]:\n",
    "    init_frames.append(create_frame(i, base_smpl))\n",
    "\n",
    "init(init_frames, body_height, b2m, debug_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103 205 307 409]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(indices_init[1:])\n",
    "print(init_frames[0].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pose frame by frame\n",
    "with h5py.File(out, 'w') as fp:\n",
    "    last_smpl = None\n",
    "    poses_dset = fp.create_dataset(\"pose\", (num_frames, 72), 'f', chunks=True, compression=\"lzf\")\n",
    "    trans_dset = fp.create_dataset(\"trans\", (num_frames, 3), 'f', chunks=True, compression=\"lzf\")\n",
    "    betas_dset = fp.create_dataset(\"betas\", (10,), 'f', chunks=True, compression=\"lzf\")\n",
    "\n",
    "    for i in xrange(num_frames):\n",
    "        if i == 0:\n",
    "            current_frame = base_frame\n",
    "        else:\n",
    "            current_frame = create_frame(i, last_smpl)\n",
    "\n",
    "        log.info('Fit frame {}'.format(i))\n",
    "        # re-init if necessary\n",
    "        reinit_frame(current_frame, prior_data['mean'], nohands, debug_rn)\n",
    "        # final fit\n",
    "        fit_pose(current_frame, last_smpl, frustum, nohands, debug_rn)\n",
    "\n",
    "        poses_dset[i] = current_frame.smpl.pose.r\n",
    "        trans_dset[i] = current_frame.smpl.trans.r\n",
    "\n",
    "        if i == 0:\n",
    "            betas_dset[:] = current_frame.smpl.betas.r\n",
    "\n",
    "        last_smpl = current_frame.smpl\n",
    "\n",
    "log.info('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
